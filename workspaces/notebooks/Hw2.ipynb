{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Homework 2\n",
    "In homework 2, we will work with log content of user in 30 days. The general idea here is we first try to analyze one day\n",
    "then apply it to a month. Thanks to **pyspark**  supporting glob pattern directory, this can be done with ease. \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4914d9e67d76fe97"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "from delta import configure_spark_with_delta_pip\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.dataframe import DataFrame\n",
    "from pyspark.sql.functions import col, to_date, when, \\\n",
    "\tinput_file_name, regexp_extract, sum, lit"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T15:06:18.055827Z",
     "start_time": "2023-10-21T15:06:17.955926Z"
    }
   },
   "id": "127052a690f1333b"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: sql.sql.extensions\n",
      "23/10/21 19:40:30 WARN Utils: Your hostname, Andrea-Le-MBP-Pro.local resolves to a loopback address: 127.0.2.2; using 192.168.1.9 instead (on interface en0)\n",
      "23/10/21 19:40:30 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/sonle/.sdkman/candidates/spark/3.4.0/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/sonle/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/sonle/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-ad25a600-ac31-4c23-9f2d-4390ab8d5131;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;2.4.0 in central\n",
      "\tfound io.delta#delta-storage;2.4.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 201ms :: artifacts dl 6ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;2.4.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.4.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-ad25a600-ac31-4c23-9f2d-4390ab8d5131\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/4ms)\n",
      "23/10/21 19:40:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "builder = (\n",
    "\tSparkSession.builder.appName(\"homework1\")\n",
    "\t.config(\"spark.driver.memory\", \"16g\")\n",
    "\t.config(\"spark.driver.cores\", 4)\n",
    "\t.config(\"sql.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "\t.config(\n",
    "\t\t\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\"\n",
    "\t)\n",
    ")\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T12:40:33.281706Z",
     "start_time": "2023-10-21T12:40:28.867841Z"
    }
   },
   "id": "89113c134976b87f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parquet is all the way\n",
    "Log content here is stored on disk in **json format** which is not well-suited for reading purpose. \n",
    "Hence, we should load and write it down as **parquet format** since parquet is more toward to analytical workload. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "768a2d637be73c1a"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "log_path = \"/Users/sonle/Documents/GitHub/spark-playground/data/log_content\"\n",
    "data_path = \"/Users/sonle/Documents/GitHub/spark-playground/data/\"\n",
    "parquet_path = \"parquet_log_content.parquet\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T12:40:33.681669Z",
     "start_time": "2023-10-21T12:40:33.622328Z"
    }
   },
   "id": "f295133acf4acecf"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Just run this function one time\n",
    "def read_log_content(\n",
    "\t\tdata_paths: str,\n",
    "\t\tparquet_path: str\n",
    "):\n",
    "\t\"\"\"\n",
    "    Read and rename log content data in json format and \n",
    "    write it to disk in parquet format with partitioning option\n",
    "    :param data_paths: data directory\n",
    "    :param parquet_path: parquet file name\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\treturn (\n",
    "\t\tspark.read.json(f\"{data_paths}/log_content/*.json\")\n",
    "\t\t.select(\n",
    "\t\t\tcol(\"_index\").alias(\"Index\"),\n",
    "\t\t\tcol(\"_type\").alias(\"Type\"),\n",
    "\t\t\tcol(\"_id\").alias(\"Id\"),\n",
    "\t\t\tcol(\"_score\").alias(\"Score\"),\n",
    "\t\t\tcol(\"_source.*\"),\n",
    "\t\t\tto_date(\n",
    "\t\t\t\tregexp_extract(input_file_name(), r\"\\d{8}\", 0),\n",
    "\t\t\t\t\"yyyyMMdd\"\n",
    "\t\t\t).alias(\"Date\")\n",
    "\t\t)\n",
    "\t\t.write.parquet(\n",
    "\t\t\tpath=f\"{data_paths}/{parquet_path}\",\n",
    "\t\t\tmode=\"overwrite\",\n",
    "\t\t\tpartitionBy=\"Date\",\n",
    "\t\t\tcompression=\"zstd\"\n",
    "\t\t)\n",
    "\t)\n",
    "\n",
    "\n",
    "read_log_content(data_path, parquet_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T13:30:21.719970Z",
     "start_time": "2023-10-21T13:27:16.201332Z"
    }
   },
   "id": "1abcbec63793b454"
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "df = (\n",
    "\tspark.read.parquet(\n",
    "\t\tf\"{data_path}/{parquet_path}\"\n",
    "\t)\n",
    "\t.filter(col(\"Contract\") != \"0\")\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T16:56:46.870011Z",
     "start_time": "2023-10-21T16:56:46.380846Z"
    }
   },
   "id": "7566fb9748a33103"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+-----+-------+---------+------------+-------------+----------+\n",
      "|  Index|   Type|                  Id|Score|AppName| Contract|         Mac|TotalDuration|      Date|\n",
      "+-------+-------+--------------------+-----+-------+---------+------------+-------------+----------+\n",
      "|history|channel|AYB79qCpa1FFivsGZAN3|    0|CHANNEL|HNH757497|405BD8A648C6|        77713|2022-04-30|\n",
      "|history|channel|AYB79qCpa1FFivsGZAN8|    0|CHANNEL|LDFD14107|802BF9BE4376|        77712|2022-04-30|\n",
      "|history|channel|AYB79qCga1FFivsGZAHn|    0|CHANNEL|SGH538814|802BF95B0E77|        78677|2022-04-30|\n",
      "|history|channel|AYB79qCpa1FFivsGZAOI|    0|CHANNEL|HND368630|4CEBBD201707|        77706|2022-04-30|\n",
      "|history|channel|AYB79qCpa1FFivsGZAON|    0|CHANNEL|BDFD59880|0C96E68E61CD|        77704|2022-04-30|\n",
      "|history|channel|AYB79qCga1FFivsGZAHx|    0|CHANNEL|HPFD87960|B84DEE853CE4|        78671|2022-04-30|\n",
      "|history|channel|AYB79qCpa1FFivsGZAOb|    0|CHANNEL|PYFD06964|0C96E6E85735|        77695|2022-04-30|\n",
      "|history|channel|AYB79qCga1FFivsGZAH7|    0|CHANNEL|NDFD38001|10394E17356B|        78666|2022-04-30|\n",
      "|history|channel|AYB79qCga1FFivsGZAH_|    0|CHANNEL|TVFD15974|10394E19A57E|        78665|2022-04-30|\n",
      "|history|channel|AYB79qCpa1FFivsGZAOq|    0|CHANNEL|HUFD27559|0C96E6C977A8|        77688|2022-04-30|\n",
      "|history|channel|AYB79qCga1FFivsGZAIM|    0|CHANNEL|NBFD20938|18473D8EB55B|        78659|2022-04-30|\n",
      "|history|channel|AYB79qCga1FFivsGZAIR|    0|CHANNEL|QTFD09280|CCEDDC5E4619|        78657|2022-04-30|\n",
      "|history|channel|AYB79qCpa1FFivsGZAO5|    0|CHANNEL|NAFD13566|485F994D7301|        77684|2022-04-30|\n",
      "|history|channel|AYB79qCga1FFivsGZAIa|    0|CHANNEL|BEFD11586|E4AB897E0996|        78654|2022-04-30|\n",
      "|history|channel|AYB79qCga1FFivsGZAIf|    0|CHANNEL|THFD22286|CCD4A1FA9A6C|        78654|2022-04-30|\n",
      "|history|channel|AYB79qCpa1FFivsGZAPF|    0|CHANNEL|NTD041113|E4AB8974D72B|        77674|2022-04-30|\n",
      "|history|channel|AYB79qCga1FFivsGZAIp|    0|CHANNEL|HNH046808|B84DEE89BD13|        78648|2022-04-30|\n",
      "|history|channel|AYB79qCga1FFivsGZAIu|    0|CHANNEL|TQFD09378|0C96E6AA1707|        78646|2022-04-30|\n",
      "|history|channel|AYB79qCpa1FFivsGZAPU|    0|CHANNEL|SGH649915|08674EDE1170|        77664|2022-04-30|\n",
      "|history|channel|AYB79qCpa1FFivsGZAPZ|    0|CHANNEL|HNH849444|1CBFC03D8BC0|        77662|2022-04-30|\n",
      "+-------+-------+--------------------+-----+-------+---------+------------+-------------+----------+\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"log_content\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T14:33:22.186615Z",
     "start_time": "2023-10-21T14:33:21.790357Z"
    }
   },
   "id": "5bf3b546b3751a52"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 71:=========>                                              (2 + 10) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|AppName|\n",
      "+-------+\n",
      "|  KPLUS|\n",
      "|  RELAX|\n",
      "|  CHILD|\n",
      "|   FIMS|\n",
      "|CHANNEL|\n",
      "|  SPORT|\n",
      "|    VOD|\n",
      "|    APP|\n",
      "|    BHD|\n",
      "+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\tsqlQuery=\"\"\"\n",
    "\tselect\n",
    "\t\tdistinct  AppName\n",
    "\t\t\n",
    "\tfrom log_content\n",
    "\t\n",
    "\t\"\"\"\n",
    ").show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T15:40:26.234594Z",
     "start_time": "2023-10-21T15:40:23.250200Z"
    }
   },
   "id": "49dcfeddbc30c8e7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ETL\n",
    "The requirements at this part is that we need to extract the information of each contract in terms of total duration of five segments \"TVDuration\", \"MovieDuration\", \"SportDuration\",\n",
    "\"ChildDuration\", \"RelaxDuration\".\n",
    "\n",
    "The first option is to **aggregate sum function manually**, the second option is to use supported **pyspark pivot** method. \n",
    "\n",
    "Since we have 5 categories, we will need to rewrite some operations repeatedly which can take some time. For example:\n",
    "```python\n",
    "when(col(\"name\") == \"some_name\", value).otherwise(value)\n",
    "# or sum method in agg method\n",
    "sum(\"columns\").alias(\"columns_name\")\n",
    "```\n",
    "Thankfully, pyspark functions support arguments unpacking `*exprs` so we can leverage this by creating lists of expressions before pasting them to pyspark functions.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fde24d42ea559c4"
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "app_map = [\n",
    "\t\"CHANNEL\",\n",
    "\t\"VOD\",\n",
    "\t\"KPLUS\",\n",
    "\t\"CHILD\",\n",
    "\t\"RELAX\",\n",
    "]\n",
    "columns_name = [\"TVDuration\", \"MovieDuration\", \"SportDuration\",\n",
    "                \"ChildDuration\", \"RelaxDuration\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T16:57:29.125795Z",
     "start_time": "2023-10-21T16:57:29.098270Z"
    }
   },
   "id": "7eabb095e1c3ba5"
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "def summarize_by_manual_pivot(\n",
    "\t\tdf: DataFrame,\n",
    "\t\tapp_names: list[str],\n",
    "\t\tcolumn_names: list[str]\n",
    ") -> DataFrame:\n",
    "\t\"\"\"\n",
    "\tFunction to manually pivot data. \n",
    "\t:param df: Dataframe, log content data\n",
    "\t:param app_names: application names in original data\n",
    "\t:param column_names: new column names after aggregation\n",
    "\t:return: new summarized data with required format\n",
    "\t\"\"\"\n",
    "\t\n",
    "\twhens = [when(col(\"AppName\") == app_name, col(\"TotalDuration\")).otherwise(lit(0)).alias(f\"{column_name}\")\n",
    "\t\t\t for app_name, column_name in zip(app_names, column_names)\n",
    "\t\t\t ]\n",
    "\t\n",
    "\texprs = [sum(x).alias(f\"{x}\") for x in column_names]\n",
    "\n",
    "\treturn (\n",
    "\t\tdf\n",
    "\t\t.select(\n",
    "\t\t\tcol(\"Contract\"),\n",
    "\t\t\t*whens)\n",
    "\t\t.groupby(\"Contract\")\n",
    "\t\t.agg(*exprs)\n",
    "\t\t.orderBy(\"TVDuration\", ascending=False)\n",
    "\t)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T16:30:44.910952Z",
     "start_time": "2023-10-21T16:30:44.905412Z"
    }
   },
   "id": "7762d4dd9edb15ae"
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 128:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-------------+-------------+-------------+-------------+\n",
      "| Contract|TVDurartion|MovieDuration|SportDuration|ChildDuration|RelaxDuration|\n",
      "+---------+-----------+-------------+-------------+-------------+-------------+\n",
      "|HPFD01358|    87334.0|         null|         null|      13491.0|         null|\n",
      "|BND016514|  1741303.0|         null|     218863.0|         null|         null|\n",
      "|NTFD09088|   854026.0|         null|         null|         null|         null|\n",
      "|TNFD18206|   790149.0|         null|         null|      60996.0|         15.0|\n",
      "|HNH585980|   650303.0|         null|         null|         null|         null|\n",
      "|HNH898380|   753701.0|         null|         null|      30749.0|         null|\n",
      "|DAFD53097|  1494819.0|         null|         null|         null|         null|\n",
      "|HNH619464|    47127.0|       5297.0|         null|       2132.0|        198.0|\n",
      "|NBFD09044|   136249.0|      63765.0|         null|         null|         null|\n",
      "|HNH729854|   689090.0|      72982.0|         null|         null|        197.0|\n",
      "|PYFD13426|   709770.0|         null|      89740.0|         null|         null|\n",
      "|HNH516027|  1156724.0|        543.0|         null|       8031.0|         null|\n",
      "|YBD003055|   760087.0|       4713.0|         null|       6164.0|         null|\n",
      "|HNJ144783|  1607789.0|         75.0|         null|         null|         null|\n",
      "|SGD100955|   637431.0|      11381.0|         null|         null|         null|\n",
      "|QND027171|    10436.0|      10600.0|         null|         null|         null|\n",
      "|BED003648|    33993.0|      12808.0|         null|         null|         null|\n",
      "|GLFD12598|       97.0|         null|         null|      10181.0|         null|\n",
      "|HND599197|    71276.0|         null|         null|      78201.0|         null|\n",
      "|HYFD60208|    68465.0|         null|         null|         null|         null|\n",
      "+---------+-----------+-------------+-------------+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 39 ms, sys: 17.7 ms, total: 56.7 ms\n",
      "Wall time: 2min 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "summarize_by_manual_pivot(df, app_names=app_map, column_names=columns_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T16:32:53.375959Z",
     "start_time": "2023-10-21T16:30:48.294465Z"
    }
   },
   "id": "46e7034f4ae866f2"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "def summarize_by_supported_pivot(\n",
    "\t\tdf: DataFrame,\n",
    "\t\tapp_names: list[str],\n",
    "\t\tcolumn_names: list[str]\n",
    ") -> DataFrame:\n",
    "\t\"\"\"\n",
    "\tFunction to pivot data using supported pyspark one\n",
    "\t:param df: \n",
    "\t:param app_names: \n",
    "\t:param column_names: \n",
    "\t:return: \n",
    "\t\"\"\"\n",
    "\texprs = [col(x).alias(f\"{y}\") for x, y in zip(app_names, column_names)]\n",
    "\n",
    "\treturn (\n",
    "\t\tdf\n",
    "\t\t.groupby(\"Contract\")\n",
    "\t\t.pivot(\"AppName\", app_names)\n",
    "\t\t.sum(\"TotalDuration\")\n",
    "\t\t.select(\n",
    "\t\t\tcol(\"Contract\"),\n",
    "\t\t\t*exprs\n",
    "\t\t)\n",
    "\t\t.orderBy(\"TVDuration\", ascending=False)\n",
    "\t)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T16:57:37.338061Z",
     "start_time": "2023-10-21T16:57:37.246799Z"
    }
   },
   "id": "6469543f8d7f1c2f"
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 141:==================================================>    (12 + 1) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------------+-------------+-------------+-------------+\n",
      "| Contract|TVDuration|MovieDuration|SportDuration|ChildDuration|RelaxDuration|\n",
      "+---------+----------+-------------+-------------+-------------+-------------+\n",
      "|NBFD21210|  26445048|       406535|       647810|         1427|           32|\n",
      "|BDD044379|  26085282|        26639|         null|         1067|          386|\n",
      "|BDFD58200|  24655135|         null|         null|         null|           93|\n",
      "|BLFD00046|  15783646|       889257|       707309|        77916|        46116|\n",
      "|DNFD92311|  15068109|       951556|       573862|       636809|       334250|\n",
      "|    PAYTV|  13490019|       239052|       455106|       267162|        11452|\n",
      "|HNH718815|  13015472|       139572|         null|       119213|        20286|\n",
      "|SGH336949|  12825697|         null|         null|          109|        87815|\n",
      "|SGFD52266|  11046008|       544069|         null|       113266|        14801|\n",
      "|SGH952911|  10373154|       402057|         null|        20854|         8778|\n",
      "|HNH235043|   9215577|        56595|         null|         4695|         5403|\n",
      "|HPD057745|   8355980|         null|         null|         null|         null|\n",
      "|HMFD07765|   8065134|         null|         null|         null|         null|\n",
      "|CBFD02956|   8058180|         null|         null|           67|         null|\n",
      "|HUFD20139|   7565308|       191893|         null|       195565|        16402|\n",
      "|CBFD05289|   7341907|         7953|         null|         null|          457|\n",
      "|HNFD93301|   7310115|         null|       225525|         null|         null|\n",
      "|HPFD91825|   7196752|        24455|         null|         null|         null|\n",
      "|DAFD33735|   7182381|        52972|         null|        20994|        20329|\n",
      "|SGFD15057|   7172659|        24329|         null|         null|         null|\n",
      "+---------+----------+-------------+-------------+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 19.4 ms, sys: 7.88 ms, total: 27.3 ms\n",
      "Wall time: 15.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "summarize_by_supported_pivot(df, app_names=app_map, column_names=columns_name)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T16:57:55.385151Z",
     "start_time": "2023-10-21T16:57:39.447980Z"
    }
   },
   "id": "21753bee715fdba6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
